{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Business Objectives","text":""},{"location":"#context","title":"Context","text":"<p>Assume you have 2 services:</p> <ul> <li>Service 1 is responsible for creating a table A</li> <li>Service 2 requires using data from that same table A</li> </ul> <p>You can modify Service 1 to change the format/schema/content of table A, like:</p> <ul> <li>Remove/Add a column</li> <li>Change the data type of a columns<ul> <li>Change from Integer to String</li> </ul> </li> <li>Change the semantic meaning of a column</li> <li>Change the constraints on the values of a column<ul> <li>Column uniqueness</li> <li>Column cannot be empty</li> <li>Column allowed values</li> </ul> </li> </ul> <p>On the other hand, the \"requirements\" from Service 2 can be more or less strict</p> <ul> <li>It only needs a subset of columns from table A</li> <li>It requires a subset of the Allowed Values for a column<ul> <li>E.g. Service 2 only cares about properties in the COUNTRY = UK, so if COUNTRY = FRANCE is removed from table A, it doesn't care.</li> </ul> </li> </ul> <p>Given the possible scenarios above, a challenge that emerges is with knowing, at time of the MR/PR (merge/pull request), if the incoming changes to one of the Services will cause Service 2's table A expectations to not be met.</p> <ul> <li>Service 1 will remove a column from table A, when that same column is required by Service 2.</li> <li>Service 2 adds a new expectation of a Column X that is not being produced by Service 1</li> </ul> <p>Additionally, even if \"on paper\" the two services agree regarding table A, it can happen that during execution, one of the services encounters data that do not match the expectations.</p> <ul> <li>Service 1 says column X cannot be empty, Service 2 expects column X to not be empty, but column X has empty values when retrieved by Service 2. Service 1 may have emitted a Warning, but whether it stops Column X from being propagated is a whole different matter.</li> </ul>"},{"location":"#goal","title":"Goal","text":"<p>The goal of Data Contracts is to allow different Services in a System to share their expectations and requirements on Tables, allowing those expectations and requirements to be compared and the system to bring awareness of potentially incompatible expectations from their Services.</p> <p>One key aspect of achieving this is making sure there is a standardised way of declaring the expectations and requirements that a Service has on a Table.</p>"},{"location":"#what-is-a-data-contract","title":"What is a Data Contract","text":"<p>A Data Contract is an artifact containing a collection of metadata about a Table. Such table can be a database table, or a \"file based\" table, like CSV, Excel or Parquet.</p> <p>A Data Contract can refer to either an Incoming Table or an Outcoming Table. If the Data Contract refers to an Outcoming Table it can be called a Producer Data Contract. On the other hand, if the Data Contract refers to an Incoming Talbe it can be called a Consumer Data Contract.</p> <p>The minimum metadata a Data Contract should contain is a list of columns in a table, alongside their description, data types and basic constraints. It could also contain more information, but those would most likely vary across the different implementations of Data Contracts.</p> <p>For a system, there should be a centralised \"data contracts catalog\", that keeps track of all \"producers\" and \"consumers\" of Data Contracts and can perform \"compatibility checks\" between them.</p> <p>In a well designed system, a table should only be \"produced\" by a single Service, whereas many Services may \"consume\" it. This leads to the constraint that \"no 2 distinct Producer Data Contracts may refer to the same Table\".</p>"},{"location":"#data-contract-implementation","title":"Data Contract Implementation","text":"<p>Data Contracts can be represented in many ways. One way that I particularly like is \"metadata only parquet files\" where the Metadata comes from an Arrow Schema. The reasons I like this are the following:</p> <ul> <li> <p>Arrow is becoming the standard way of manipulating data in a Service, and Arrow is itself a \"universal standard\" that has implementations in all mainstream programming languages like Python, Java, Rust, Javascript, Go, R, etc.</p> <ul> <li>This means that the Data Contracts are agnostic of what programming language was used to create it.</li> </ul> </li> <li> <p>Arrow Schemas contain not only the list of columns and their types, but also allow the adition of Custom Metadata to both individual Columns and to the whole table.</p> <ul> <li>This Custom Metadata can contain virtually anything. In particular, it can contain Column descriptions, the specification of column tests, etc, and within a System the distinct Services should agree on how to use the Custom Metadata</li> </ul> </li> <li> <p>You can very easily write an Arrow Schema in several languages and save it to a Metadata Only Parquet File</p> </li> </ul>"},{"location":"Design/","title":"Design","text":"<ul> <li>Create Field and Table metadata with class adc.Metadata()</li> <li>Create Arrow schema with Field Names and Types, and metadata value coming from class Metadata</li> <li> <p>Create DataContract giving it a name, a schema and a direction.</p> </li> <li> <p>As part of the CICD pipeline, call <code>adc check</code>.</p> <ul> <li>This will crawl the directory found in pyproject.toml file or env var X to build the ServiceCatalog object. The ServiceCatalog contains a mapping of all Contract Names found and their corresponding DataContract object</li> <li>Will call method <code>generate_files</code> to create all Metadata Only Parquet Files for the Service</li> <li>Will connect to the CatalogRepository and fetch all relevant existing DataContracts from other services</li> <li>Will run the SchemaCompatibility check between all relevant DataContract and yield a compatibility report for each check</li> </ul> </li> <li> <p>If <code>adc check</code> doesn't raise any failures, then call <code>adc upload</code></p> <ul> <li>Will call method <code>upload_catalog_files</code> of CatalogRepository to replace the existing Service Data Contracts with the new ones coming from the PR/MR.</li> </ul> </li> </ul>"},{"location":"Getting%20Started/","title":"Getting Started","text":"<p>On your python project, ha</p>"},{"location":"Roadmap/","title":"Roadmap","text":"<ul> <li>Improve SchemaCompatibility class to handle nested fields</li> <li>Improve Metadata Class to allow custom SQL tests</li> </ul>"}]}